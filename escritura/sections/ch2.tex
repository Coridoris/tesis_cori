\section{Participantes}\label{paracitar}
Acá tengo que contar la edad de los participantes, el género y esas cosas como estan en los papers
\section{Entrevista Autobiográfica}
aca tengo que contar el experimento que vinieron 65 personas a contar relatos libres de memorias autobiográficas sobre cuatro eventos del 2022 y un evento de control que era la memoria no consolidada. Cómo se seleccionaron los eventos? PONER LA ELECCIÓN DE LOS EVENTOS EN APÉNDICE: Los eventos se seleccionaron buscando los eventos mas relevantes del 2022 en diarios, tendencias de google y tendencias de tw. Se realizó una encuesta con los 30 eventos del 2022 a 100 personas contar estas 100 personas la edad y esas cosas. Mostrar gráfico de intensidad vs valencia de los eventos seleccionados, cuánto recordaron de cada uno en presencial solo de menores de 30. 
Del experimento tengo que contar que venian a hablar, antes se les hacia el cuestionario de Memorias autobográficas el día antes. El día de la entrevista al llegar se les mostraba una instrucción donde se les contaba de que constaba el experimetnto y se relataba que contaran de sobre sus vivencias propias el día que se enteraron del evento sobre el que se les iba a preguntar. Se arrancaba con un relato control para que entraran en calor, el relato no consolidado y dsp se preguntaba en orden aleatorio por los otros 4 eventos. Las ques se presentaban con diapositivas que pasaban ellos. Se grababa un audio de los relatos. Después de la entrevista se hacía las mismas preguntas que se hicieron para seleccionar los eventos: cuáto recordaron y la intensidad y valencia del sentimiento al recordar. Esto se repitió nuevamente 5 meses después a esta entrevista retornaron un x porciento de los participantes nuevamente demografía de los mismos.
Los relatos se grababan y transcribian usando whisper el paquete large, después pasaban por una corrección humana ya que whisper asegura un 98 porciento correcta al transcripción. Se corregía las palabras y la puntuación.
\section{Herramientas NPL}

Para analizar los relatos se introdujeron herramientas de NLP (tengo q hablar de NLP en la intro) buscando cuantificadores de los relatos que nos dejen estudiar los mismos separanado por bla y bla. Lo primero que se hizo fue descartar outliers contando la cantidad de palabras únicas en los relatos descartando a las personas a 3 MADs de distancias de la media (CITAR PAPER SUEÑOS DE ITBA DONDE HACEN ESTO), dejo cuántas personas tienen cada relato? No, mejor solo pongo el porcentaje que descarta esto. Las variables se separaron en 4 categorías, ponerlas con subindices y explicarlas. contenido sentimiento estructurales y memoria.
\section{Reducción de dimensionalidad y clustering}
aca contar de PCA (de TSNE no pero decir que se probaron otros algoritmos de reducción de dimensionalidad y se decidió por este). Contar de clustering, decir que se usaron otros métodos pero daban todos parecidos entre kmedoids kmeans y jerarquico con average y se decidió por kmeans porque era levemente mejor. Contar del índice R (ve performance con data externa), las matrices de confusión, silhouette (ve performance con respecto a lo interno).

Toca explicar el quilombo que hice para separar, que primero fue presencial vs filler, de silhouette se define k, de R el nro de PCs, y viendo las PCs se toman las variables mas significativas de estas PCs, explicar el criterio de cómo se eligen esas variables, y que se hace un barrido. Se tienen las PCs que maximizan esta separación. Se ve que pasa en el segundo con ESTAS PCs.
Después se busca separar cfk, ar y campeones, primero buscamos usando todas las vars nro pcs vs k silhouette y se definió k, dsp  n vs nro pcs una matriz del R pare definir n y nro PCs. Se tienen las PCs que maximizan la separación en el primer tiempo. Se ve que pasa en el segundo tiempo con ESTAS PCs.

Se pasa a comparar los dos tiempos las PCs que separaban cfk ar y camp se usan para comparar en el primer tiempo vs en el segundo usando ANOVA a ver si hay diferencias entre las medias. Se hizo condición a condición.